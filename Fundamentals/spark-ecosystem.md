# Spark Components

1. Core API - Basic functionality of Spark. Also, the host for the API that defines RDD. These RDDs are a Sprak central programming abstraction. We can use Spark with R, Python, Scala, SQL or Java.
2. SQL - Package for working with structured data. It allows querying data via SQL or Hive. It supports various sources.
3. Streaming - Enables processing of live streams of data. Spark streaming provides an API for manipulating data streams that are similar to Spark Core's RDD API.
4. MLlib - Provides multiple types of machine learning algorithms, like classification, regression, clustering, etc.
5. GraphX - Library for manipulating graphs and performing graph-parallel computations.
